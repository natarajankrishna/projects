{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOx2kaO5sP3uB06kg+1kIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natarajankrishna/projects/blob/computer-vision/vehicle_motion_detection_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8LUzS7fSH9v"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture('media/videos/carsvid.mp4')\n",
        "\n",
        "kernel = None\n",
        "\n",
        "backgroundObject = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    foreground_mask = backgroundObject.apply(frame)\n",
        "\n",
        "\n",
        "    _, foreground_mask = cv2.threshold(foreground_mask, 250, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "\n",
        "    foreground_mask = cv2.erode(foreground_mask, kernel, iterations = 1)\n",
        "    foreground_mask = cv2.dilate(foreground_mask, kernel, iterations = 2)\n",
        "\n",
        "    contours, _ = cv2.findContours(foreground_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    frameCopy = frame.copy()\n",
        "    \n",
        "    # loop over each contour found in the frame.\n",
        "    for cnt in contours:\n",
        "\n",
        "        # We need to be sure about the area of the contours i.e. it should be higher than 400 to reduce the noise.\n",
        "        if cv2.contourArea(cnt) > 400:\n",
        "            \n",
        "            # Accessing the x, y and height, width of the cars\n",
        "            x, y, width, height = cv2.boundingRect(cnt)\n",
        "            \n",
        "            # Here we will be drawing the bounding box on the cars\n",
        "            cv2.rectangle(frameCopy, (x , y), (x + width, y + height),(0, 0, 255), 2)\n",
        "            \n",
        "            # Then with the help of putText method we will write the 'Car detected' on every car with a bounding box\n",
        "            cv2.putText(frameCopy, 'Car Detected', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0), 1, cv2.LINE_AA)\n",
        "\n",
        "            \n",
        "    foregroundPart = cv2.bitwise_and(frame, frame, mask=foreground_mask)\n",
        "    stacked_frame = np.hstack((frame, foregroundPart, frameCopy))\n",
        "\n",
        "    cv2.imshow('Original Frame, Extracted Foreground and Detected Cars', cv2.resize(stacked_frame, None, fx=0.5, fy=0.5))\n",
        "\n",
        "    \n",
        "    k = cv2.waitKey(1) & 0xff\n",
        "    \n",
        "    if k == ord('q'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "sjfZi1cJUgSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}